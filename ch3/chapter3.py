import tensorflow as tf

"3. 텐서플로를 사용한 선형 및 로지스틱 회귀"

"3.1 수학 복습"

"3.1.1 함수와 미분가능성"
''' (2차함수 이상에서 최소값, 최대값을 미분으로 찾고 이것이 의미있다는 내용) 
고수준에서의 머신러닝은 단순히 함수를 최소화하는 기술입니다. 학습 알고리즘은 적합하게 정의된 함수의 최소점을 찾은 것에 지나지 않습니다.
이러한 정의는 수학적으로 단순하다는 장점이 있습니다. 그렇다면 최소점에 유용한 해결책을 가지는 특별한 미분 가능 함수는 무엇이며 어떻게 이것을 찾을 수 있을까요?'''

"3.1.2 손실 함수"
'''
당면한 실세계 문제에 대한 해결책을 가지고 있는 함수를 만드는 방법을 알아야 합니다. 머신러닝 논문들에는 이러한 인코딩을 수행하는
손실 함수(loss function)의 풍부한 역사가 담겨있습니다. 실용적인 머신러닝이란 사용 가능한 여러 종류의 손실 함수를 이해하고 
어떤 손실 함수가 어던 문제에 적용되어야 하는지를 아는 것입니다.

실세계에 적용할 수 있도록 조건을 만족하는 함수를 만드는듯..

(분류와 회귀)
크게 지도 문제와 비지도 문제.
지도 머신러닝은 분류와 회귀 두 개의 하위 문제로 나눌 수 있습니다. 분류 문제는 주어진 데이터포인트에 대해 0 또는 1 (또는 일반적으로 0, ..., n)의 이산 레이블로 할당하는
머신러닝 시스템을 설계하는 문제입니다. 회귀는 주어진 데이터포인트에 실젯값의 레이블로 (실수 R 중에서) 할당하는 머신러닝 시스템을 설계하는 문제입니다.
대부분의 머신러닝은 복잡한 실세계 시스템을 적절하고 간단한 미분 가능한 함수로 바꾸는 단순한 기술

(손실)
L^2 손실('엘투 손실') 은 일반적으로 회구 문제에 사용됩니다.
두 벡터간의 거리를 정의하고 함수를 만들어서 예측 가능하도록 만드는듯.. 나도 몰라

(확률분포)
이산 true or false같이 이산 선택과 관련된 문제를 해결하기 위해 미적분학이나 텐서플로 시스템을 어떻게 쓸거냐?
바로 확률분포(probability distribution)을 이용한다 이 말이야.

(교차 엔트로피 손실)
교차 엔트로피(cross entropy)는 두 확률분포 사이의 거리를 측정하는 수학적 방법입니다.
(식)
두 가지 결과를 가진 이산 시스템의 실제 데이터와 머신러닝 시스템으로 예측한 값의 교차 엔트로피 손실을 나타내는 식이 있고,
경험상 이 엔트로피를 최소하하는것이 제공된 훈련 데이터의 레이블을 올바르게 재현하는 분류기를 만든다고 한다.

'''

"3.1.3 경사 하강법"
'''
실제로 적절한 함수로 인코딩 했다고 치자. 어떻게 최소점을 찾을거냐?
우리가 사용할 핵심 기법은 경사 하강법(gradient descdent)에 의한 최소화. 함수 f가 가중치 W에 의존한다고 가정. (delta)W는 f를 최대로 증가시키는 W의 방향 변화. 반대 방향으로 이동하면 
f의 최소점에 가까워집니다.
경사 하강법은 반복적으로 음의 방향 기울기를 따라 함수의 최소점을 찾는 기법입니다.
W = W - a(delta)W . a 는 스텝 크기(step-size)
일반적으로 업데이트를 수행하는 반복 프로세스ㅡㄹ 가중치 행렬 W를 학습한다고 합니다.

에폭(epoch) 개념은 경사 하강법 알고리즘을 데이터 x 전체에 대해 훑어보는 것. 에폭은 주어진 미니배치 크기에서 모든 데이터를 훑어보기 위해 얼마나 많은 경사 하강법 스텝이 필요한가로 구성됩니다.
만약  데이터셋이  1000개의  데이터포인트를  가지고 있고  학습 시  미니배치의  크기는 50  이라고  가정합니다.  그러면  에폭은  20개의 경사 하강법 업데이트로 구성될 것입니다.
초기 에폭은 손실 함수를 매우 크게 감소시킬 것입니다. 이걸 사전학습. 갈수록 작아진다.
에폭 수에 따라 손실 함수의 감소를 추첮갛는 것은 학습 프로세스를 이해하는 데 시각적으로 유용할 수 있습니다. 이러한 그래프는 종종 손실 곡선으로 불립니다.
'''

"3.1.4 자동 미분 시스템"
'''
원래 미분 할라면 사람이 해야했지만 컴퓨터로 하는 방법 알아냈다.. 걍 써라
'''

"3.2 텐서플로를 사용한 학습"

"3.2.1 토이 데이터셋 만들기"
import numpy as np
np.zeros((2,2))
"""array([[0., 0.],
       [0., 0.]])"""
np.eye(3)
"""array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]])"""


# 이 책에선 선형회귀와 분류 2가지를 보이므로 파일을 나눠서 작성함.
# chapter3_linear.py 는 3-2 예제 작성
# chapter3_ligistic 은 3-3 예제 작성

"3.2.2 샐운 텐서플로 개념"

'''
플ㄹ에시ㅡ홀더(placeholder)는 텐서플로 계산ㅇ 그래프에 정보를 입력하는 방법입니다.
플레이스홀더를 텐서플로에 정보가 들어가는 입력 노드로 생각해봅시다.
플레이스홀더를 생성하는데 사용되는 핵심 함수는 tf.placeholder입니다.
'''

tf.placeholder(tf.float32, shape=(2,2))
"""<tf.Tensor 'Placeholder:0' shape=(2, 2) dtype=float32>"""

'''
회귀 및 분류 알고리즘에 데이터포인트 x와 레이블 y를 넣기 위해 플레이스홀더를 사용할 것입니다.
'''

'''
sess.run(var) 같이 플레이스홀더는 어떻게 넣냐? 피드 딕셔너리(feed dictionary)로 넣는다. 피드 딕셔너리는 텐서플로 계산 그래프에 대한 입력으로 보는 것이 가장 좋습니다.
출력은 페치(fetch) 페치는 텐서(들)로서, 그 값은 계산이 완료된 계산 그래프로부터 가져오며, 이 계산 시 피드 딕셔너리로부터 받은 플레이스홀더 값이 사용됩니다.
'''

a = tf.placeholder(tf.float32, shape=(1,))
b = tf.placeholder(tf.float32, shape=(1,))
c = a+b
with tf.Session() as sess:
    c_eval = sess.run(c, {a: [1.], b:[2.]})
    print(c_eval)
"""[3.]"""

'''
앞으로 많은 변수들을 다루게 될 텐데 tf.name_scope(name) 으로 관리하게 될 것이다.
동일한 네임 스코프 내에서 자동으로 그래프 원소를 그룹화하는 것을 지원하기 때문입니다.
'''

N=5
with tf.name_scope("placeholders"):
    x = tf.placeholder(tf.float32, (N,1))
    y = tf.placeholder(tf.float32, (N))
x
"""<tf.Tensor 'placeholders/Placeholder:0' shape=(5, 1) dtype=float32>"""
# 위에서 이 name_scope 없이 만든 <tf.Tensor 'Placeholder:0' shape=(2, 2) dtype=float32> 과는 다르다.

'''
텐서플로는 tf.train 몯ㄹ에서 최적화 알고리즘 컬렉션을 제공합니다. 앞에서 했던 경사 하강법 같은거. W = W - a(delta)W
많은 옵티마이저가 있지만 초보자는 tf.train.AdamOptimizer 나 써라
'''

# 예제 3-7은 미리 정의된 손실 l을 최소화하는 옵티마이저를 계산 그래프에 추가하는 잛은 코드입니다.
# # 예제 3-7) 텐서플로 연산 그래프에 Adam 옵티마이저 추가하기
# learning_rate = .001
# with tf.name_scope("optim"):
#     train_op = tf.train.AdamOptimizer(learning_rate).minimize(l)

'''
대부분의 유스케이스는 tf.train을 다시 구현할 필요가 없지만 디버깅 목적으로 기울기를 직접 확인하는 것은 유용하다.
이때 tf.gradients는 유용한 도구입니다.
'''

W = tf.Variable((3,))
l = tf.reduce_sum(W)
gradW = tf.gradients(l,W)
gradW
"""[<tf.Tensor 'gradients/Sum_grad/Tile:0' shape=(1,) dtype=int32>]"""

'''
이 코드는 학습 가능한 매개변수 (tf.Variable) W에 대한 손실 l의 기울기를 기호고 표시합니다.
tf.gradients는 기울기의 리스트를 반환하고 기울기 자체가 텐서입니다.
'''

'''
텐서 프로그램의 구조에 대한 시각적 이해를 얻는 것은 매우 유용합니다. 그래서 텐서보드를 제공한다.
텐서보드는 텐서플로의 다양하고 유용한 시각화를 보여주는 웹 서버(기본 설정은 localhost)를 시작합니다.
근데 볼라면 사용자가 직접 로그 파일을 만들어야 한다.
tf.grain.FileWriter()는 텐서보드 프로그램의 로깅 디렉터리를 지정하고 tf.summary는 다양한 텐서플로 변수의 요약ㅇ 정보를 지정한 로깅 디렉터리에 기록합니다.
이 장에서는 손실 함수의 값을 추적하기 위해 스칼라 값을 요약한 tf.summary.scalar만든 사용합니ㅏㄷ.
 tf.summary.merge_all()는 편의를 위해 다양한 요약을 하나의 요약으로 합치는 유용한 로깅 도구입니다.
밑 코드는 손실에 대한 요약을 합치고 로깅 디렉터리를 지정합니다.
'''
# with tf.name_scope("summaries"(:
#     tf.summary.scalar("loss",l)
#     merged = tf.summary.merge_all()
#
# train_writer = tf.summary.FileWriter('\tmp\lr-reain',tf.get_default_graph())

'''
반복적으로 경사 하강법 수행 방법? 파이썬의 for 루프를 쓴다. 각각의 반복에서 그래프로부터 합쳐진 요약인 merged와 손실 1과 함께
train_op를 가져오기 위해서 sess.run()을 사용합니다. 피드 딕셔너리르 사용하여 모든 데이터포인트와 레이블을 sess.run()에 넣습니다.
밑은 간단한 예
'''
# n_steps = 1000
# with tf.Session() as sess:
#     sess.run(tf.global_variables_initializer())
#     # 모델 학습
#     for i in range(n_steps):
#         feed_dict = {x: x_np, y: y_np}
#         _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)
#         print("step %d, loss: %f" % (i,loss))
#         train_writter.add_summary(summary, i)

"3.3 텐서플로에서 선형 모델 및 로지스틱 모델 학습하기"
#각 파일로 넘어감

'''
경사 하강법은 지역 최소점(local minimaum) 이라는 함정에 빠질 수 있지만 아직 좋은 대체 알고리즘이 없다.
'''

"3.4 마치며"

'''
텐서플로를 사용하여 간단한 학습 시스템을 구추하고 학습하는 방법
손실 함수와 경사 하강법을 포함한 기초겆ㄱ인 수학 개념, 플레이스홀더, 스코프, 텐서보드, 선형회귀 및 로지스틱 회귀 시스템 사례
'''